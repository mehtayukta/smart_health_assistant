{"cells":[{"cell_type":"code","execution_count":null,"id":"5e27971f","metadata":{"id":"5e27971f"},"outputs":[],"source":["# Modeling"]},{"cell_type":"code","source":["!pip install fuzzywuzzy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wg_Zrk1-c-wg","executionInfo":{"status":"ok","timestamp":1701065549616,"user_tz":480,"elapsed":16861,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"da49486b-16d5-4084-ace9-149410ad5696"},"id":"Wg_Zrk1-c-wg","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n"]}]},{"cell_type":"code","execution_count":null,"id":"75435750","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75435750","executionInfo":{"status":"ok","timestamp":1701065576170,"user_tz":480,"elapsed":23805,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"b9d88aeb-d892-49a0-afa9-d54712f70efd"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n","  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, matthews_corrcoef\n","from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, log_loss\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import pickle\n","from sklearn.feature_selection import VarianceThreshold\n","from fuzzywuzzy import process\n","from sklearn.model_selection import GridSearchCV\n","import time\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","#Connecting the driver\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"id":"ac49f510","metadata":{"id":"ac49f510"},"outputs":[],"source":["from sklearn.datasets import make_blobs\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import GradientBoostingClassifier"]},{"cell_type":"code","execution_count":11,"id":"89d98298","metadata":{"id":"89d98298","executionInfo":{"status":"ok","timestamp":1701072450208,"user_tz":480,"elapsed":291,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def accuracy_measure(y_test, y_pred):\n","    sensitivity_overall = recall_score(y_test, y_pred, average='weighted')\n","    print('Sensitivity Overall Data:',sensitivity_overall)\n","\n","    precision_overall = precision_score(y_test, y_pred, average='weighted')\n","    print('Precision Overall Data:',precision_overall)\n","\n","    f1_overall = f1_score(y_test, y_pred, average='weighted')\n","    print('F1 Score Overall Data:',f1_overall)\n","\n","    # Cohen's Kappa statistic\n","    kappa = cohen_kappa_score(y_test, y_pred)\n","    print(\"Cohen's Kappa:\", kappa)\n","\n","    # Matthews Correlation Coefficient (MCC)\n","    mcc = matthews_corrcoef(y_test, y_pred)\n","    print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n","\n","    # Compute log loss\n","    # logloss = log_loss(y_test, y_pred)\n","    # print(f\"Log Loss: {logloss}\")\n","\n","    # # AUC and ROC\n","    # fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n","    # roc_auc = auc(fpr, tpr)\n","\n","    # # Plot ROC curve\n","    # plt.figure(figsize=(8, 6))\n","    # plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","    # plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    # plt.xlabel('False Positive Rate')\n","    # plt.ylabel('True Positive Rate')\n","    # plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    # plt.legend(loc='lower right')\n","    # plt.show()\n","\n","    # # Visualize predicted probabilities distribution\n","    # plt.figure(figsize=(8, 6))\n","    # sns.histplot(y_pred, bins=20, kde=True, color='skyblue')\n","    # plt.xlabel('Predicted Probabilities')\n","    # plt.ylabel('Frequency')\n","    # plt.title('Distribution of Predicted Probabilities')\n","    # plt.show()\n","\n","    # # Confusion Matrix\n","    # cm = confusion_matrix(y_test, y_pred)\n","    # print(cm)\n","\n","    # # Printing Confusion Matrix calsswise\n","    # unique_classes = np.unique(y_test)\n","\n","    # # Initialize variables to store metrics\n","    # total_tp = 0\n","    # total_tn = 0\n","    # total_fp = 0\n","    # total_fn = 0\n","\n","    # Iterate over each class\n","    # for cls in unique_classes:\n","    #     idx = (y_test == cls)\n","    #     true_positive = np.sum((y_pred[idx] == cls))\n","    #     true_negative = np.sum((y_pred != cls) & (y_test != cls))\n","    #     false_positive = np.sum((y_pred == cls) & (y_test != cls))\n","    #     false_negative = np.sum((y_pred != cls) & (y_test == cls))\n","\n","    #     total_tp += true_positive\n","    #     total_tn += true_negative\n","    #     total_fp += false_positive\n","    #     total_fn += false_negative\n","\n","    #     print(f\"\\nClass {cls} Metrics:\")\n","    #     print(f\"True Positive (TP): {true_positive}\")\n","    #     print(f\"True Negative (TN): {true_negative}\")\n","    #     print(f\"False Positive (FP): {false_positive}\")\n","    #     print(f\"False Negative (FN): {false_negative}\")\n","\n","    # # Consolidated results\n","    # print(\"\\nConsolidated Results:\")\n","    # print(f\"Total True Positive (TP): {total_tp}\")\n","    # print(f\"Total True Negative (TN): {total_tn}\")\n","    # print(f\"Total False Positive (FP): {total_fp}\")\n","    # print(f\"Total False Negative (FN): {total_fn}\")\n"]},{"cell_type":"markdown","source":["Gradient boost without dimensionality reduction\n","\n","---\n","\n"],"metadata":{"id":"NVhRXMgsVQ_c"},"id":"NVhRXMgsVQ_c"},{"cell_type":"code","source":["df_training = pd.read_csv(\"/content/drive/MyDrive/DAP/python_scripts/training_dataset_final.csv\")\n","X =df_training.drop(columns=['disease'])\n","y =df_training['disease']\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","# Print the shapes of the resulting sets\n","print(\"Training set:\", X_train.shape, y_train.shape)\n","print(\"Validation set:\", X_val.shape, y_val.shape)\n","print(\"Test set:\", X_test.shape, y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3fqd3G2VTqA","executionInfo":{"status":"ok","timestamp":1701065592601,"user_tz":480,"elapsed":2997,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"b5fe7bce-23f7-4adb-80cb-c45f94d0dcef"},"id":"h3fqd3G2VTqA","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (8668, 404) (8668,)\n","Validation set: (1858, 404) (1858,)\n","Test set: (1858, 404) (1858,)\n"]}]},{"cell_type":"code","source":["print('####### Gradient boost without dimensionality reduction')\n","classifier = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,subsample=0.8,random_state=10)\n","time_now=time.time()\n","classifier.fit(X_train, y_train)\n","print('time taken: ',time.time()-time_now)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGt5_gqmYOBt","executionInfo":{"status":"ok","timestamp":1701074466283,"user_tz":480,"elapsed":1953576,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"943ea2fc-82ed-4c47-f2a2-7001076fe820"},"id":"xGt5_gqmYOBt","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["####### Gradient boost without dimensionality reduction\n","time taken:  1953.2482314109802\n"]}]},{"cell_type":"code","source":["# Make predictions on the test set\n","y_pred_basline = classifier.predict(X_test)\n","accuracy_baseline = accuracy_score(y_test, y_pred_basline)\n","print(\"Test Accuracy Score:\", accuracy_baseline)\n","accuracy_measure(y_test, y_pred_basline)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtnzQaho8T2D","executionInfo":{"status":"ok","timestamp":1701074523049,"user_tz":480,"elapsed":3340,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"3ed62145-c272-4fd4-f357-fdd9563dc1ca"},"id":"mtnzQaho8T2D","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy Score: 0.8972012917115177\n","Sensitivity Overall Data: 0.8972012917115177\n","Precision Overall Data: 0.9053183481209972\n","F1 Score Overall Data: 0.8970338154218543\n","Cohen's Kappa: 0.8962877236973424\n","Matthews Correlation Coefficient (MCC): 0.8963854372972909\n"]}]},{"cell_type":"markdown","id":"4a1f4bb3","metadata":{"id":"4a1f4bb3"},"source":["### Using various dimensionality reduction"]},{"cell_type":"code","execution_count":15,"id":"0b3d514f","metadata":{"id":"0b3d514f","executionInfo":{"status":"ok","timestamp":1701074550940,"user_tz":480,"elapsed":231,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def low_var():\n","    df_low_variance = pd.read_csv(\"/content/drive/MyDrive/DAP/python_scripts/low_variance_features.csv\")\n","    df_low_variance= df_low_variance.fillna(0)\n","    df_low_variance.isna().any()\n","    X = df_low_variance.drop('disease', axis=1)\n","    y = df_low_variance['disease']\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","    return X,y,X_train,y_train,X_test,X_val,y_test, y_val\n","\n","def rand_forest():\n","    df_training = pd.read_csv(\"/content/drive/MyDrive/DAP/python_scripts/training_dataset_final.csv\")\n","    df_feature = pd.read_csv(\"/content/drive/MyDrive/DAP/python_scripts/feature_importance_df.csv\")\n","    df_feature= df_feature.fillna(0)\n","    df_training= df_training.fillna(0)\n","\n","    feature_list=(df_feature['Feature'].head(100)).tolist()\n","    df_training_important_Features = df_training[feature_list]\n","    df_training_important_Features['disease'] = df_training['disease']\n","    df_training_important_Features.info()\n","    X =df_training_important_Features.drop(columns=['disease'])\n","    y =df_training_important_Features['disease']\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","    return X,y,X_train,y_train,X_test,X_val,y_test, y_val\n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"2e904119","metadata":{"id":"2e904119"},"source":["# Gradient boost"]},{"cell_type":"code","execution_count":16,"id":"417a267b","metadata":{"id":"417a267b","executionInfo":{"status":"ok","timestamp":1701074668357,"user_tz":480,"elapsed":251,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def gradient_boost(X,y,X_train,y_train,X_test,X_val,y_test, y_val,pickle_file_name):\n","    classifier = GradientBoostingClassifier()\n","    classifier.fit(X_train, y_train)\n","\n","    # Make predictions on the test set\n","    print('####### Gradient boost without specifying any parameters')\n","    y_pred = classifier.predict(X_test)\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(\"Test Accuracy Score:\", accuracy)\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    print(\"F1 Score:\", f1)\n","    # ----------------------------------------------------------------------\n","\n","    # Performing Grid Search using hyperparamters\n","    print('\\n####### Gradient boost with grid search')\n","    param_test1 = {'n_estimators':range(40,81,10),'max_features':[\"log2\",\"sqrt\"]}\n","    clf = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,subsample=0.8,random_state=10),\n","    param_grid = param_test1, n_jobs=4)\n","    best_clf = clf.fit(X_train, y_train)\n","\n","    cv_results = pd.DataFrame(best_clf.cv_results_)\n","    print (f'Accuracy: {best_clf.score(X,y):.3f}')\n","    print(best_clf)\n","    best_params = best_clf.best_params_\n","    print(\"Best hyperparameters:\", best_clf.best_params_)\n","    print(\"Best model:\", best_clf.best_estimator_)\n","\n","    best_params = best_clf.best_params_\n","    # Create a Gradient boost model with the best hyperparameters\n","    best_gb_model = GradientBoostingClassifier(**best_params, learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,subsample=0.8,random_state=10)\n","\n","    # Train the model on the training data\n","    model = best_gb_model.fit(X_train, y_train)\n","\n","    # Make predictions on the testing data\n","    y_pred = best_gb_model.predict(X_test)\n","\n","    # Evaluate the performance of the model\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(\"Accuracy score:\", accuracy)\n","    print('\\n####### Cross Validation')\n","    cv_scores = cross_val_score(best_gb_model, X_train, y_test, cv=5)\n","    print('Scores from cross-validation is: ', cv_scores)\n","    print('Average accuracy from cross-validation is: {}'.format(np.mean(cv_scores)))\n","\n","    accuracy_measure(y_test, y_pred)\n","    # ----------------------------------------------------------------------\n","\n","    ### Validating the model\n","    print('\\n####### Validating the model')\n","    predicted_class_validation = best_gb_model.predict(X_val)\n","    print(\"Predicted class:\", predicted_class_validation)\n","\n","    accuracy = accuracy_score(y_val, predicted_class_validation)\n","    print(\"Accuracy on the validation set:\", accuracy)\n","    accuracy_measure(y_val, predicted_class_validation)\n","\n","    ### Saving the model with best parameters logistic regression\n","    print( \"\\n####### Saving the model with best parameters gradient boost\" )\n","    # Save the model to a file using pickle\n","    with open(pickle_file_name, 'wb') as file:\n","        pickle.dump(model, file)\n"]},{"cell_type":"markdown","source":["Gradient Boost after dimensionality reduction with Low Filter Variance"],"metadata":{"id":"xgQYo5RCUkE_"},"id":"xgQYo5RCUkE_"},{"cell_type":"code","execution_count":17,"id":"306cd69b","metadata":{"id":"306cd69b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701074678050,"user_tz":480,"elapsed":1095,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"afc835ec-a214-46e7-88be-ddfbd9481970"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training set: (8668, 104) (8668,)\n","Validation set: (1858, 104) (1858,)\n","Test set: (1858, 104) (1858,)\n"]}],"source":["X,y,X_train,y_train,X_test,X_val,y_test, y_val = low_var()\n","# Print the shapes of the resulting sets\n","print(\"Training set:\", X_train.shape, y_train.shape)\n","print(\"Validation set:\", X_val.shape, y_val.shape)\n","print(\"Test set:\", X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":18,"id":"ee15847f","metadata":{"id":"ee15847f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701074682315,"user_tz":480,"elapsed":371,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"8ca1d80c-a322-40f0-868a-f2284b21ff9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Done\n"]}],"source":["with open(r'low_var_features.txt', 'w') as fp:\n","    for item in X_train:\n","        # write each item on a new line\n","        fp.write(\"%s\\n\" % item)\n","    print('Done')"]},{"cell_type":"code","execution_count":null,"id":"4c4d2d4d","metadata":{"id":"4c4d2d4d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"605b4522-5520-4b80-db18-fd52a60b7b6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["####### Gradient boost without specifying any parameters\n","Test Accuracy Score: 0.9413347685683531\n","F1 Score: 0.9394152447602064\n","\n","####### Gradient boost with grid search\n"]}],"source":["gradient_boost(X,y,X_train,y_train,X_test,X_val,y_test, y_val,'gradient_boost_model_lv.pkl')"]},{"cell_type":"code","source":[],"metadata":{"id":"gPvETNJtUR4q"},"id":"gPvETNJtUR4q","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gradient Boost after dimensionality reduction with Random Forest"],"metadata":{"id":"02OyXfsKUSZn"},"id":"02OyXfsKUSZn"},{"cell_type":"code","execution_count":null,"id":"48c00263","metadata":{"id":"48c00263"},"outputs":[],"source":["X,y,X_train,y_train,X_test,X_val,y_test, y_val = rand_forest()"]},{"cell_type":"code","execution_count":null,"id":"b48a3201","metadata":{"id":"b48a3201"},"outputs":[],"source":["with open(r'rand_for_features.txt', 'w') as fp:\n","    for item in X_train:\n","        # write each item on a new line\n","        fp.write(\"%s\\n\" % item)\n","    print('Done')"]},{"cell_type":"code","execution_count":null,"id":"afff3a0f","metadata":{"id":"afff3a0f"},"outputs":[],"source":["gradient_boost(X,y,X_train,y_train,X_test,X_val,y_test, y_val,'gradient_boost_model_rd.pkl')"]},{"cell_type":"code","execution_count":null,"id":"882e852f","metadata":{"id":"882e852f"},"outputs":[],"source":["with open('gradient_boost_rd.pkl', 'rb') as file:\n","    loaded_model = pickle.load(file)"]},{"cell_type":"markdown","id":"0e35ce2e","metadata":{"id":"0e35ce2e"},"source":["### Predicting the Disease"]},{"cell_type":"code","execution_count":null,"id":"5f879844","metadata":{"id":"5f879844"},"outputs":[],"source":["# getting primitive care\n","df_primitive_care = pd.read_csv(\"prec_t.csv\")\n","diagnose_list = df_primitive_care['diagnose'].tolist()\n","df_primitive_care.head(3)\n"]},{"cell_type":"code","execution_count":null,"id":"7245d747","metadata":{"id":"7245d747"},"outputs":[],"source":["def predicting_disease(syp,diagnose_list,feature_names):\n","    columns_list=feature_names.copy()\n","    for col in syp:\n","        if col not in feature_names:\n","            #print(col)\n","            syp.remove(col)\n","\n","    temp_df = pd.DataFrame(0, index=[0], columns=columns_list)\n","    temp_df.loc[0, syp] = 1\n","    print(syp)\n","    print(temp_df)\n","    predicted_class_1 = loaded_model.predict(temp_df)\n","    #print(\"Predicted class:\", predicted_class_1)\n","    # getting primitive care\n","    predicted_class_1 = str(predicted_class_1)\n","    diagnose_list = [str(item) for item in diagnose_list]\n","    best_match, similarity_score = process.extractOne(predicted_class_1, diagnose_list)\n","    threshold = 70\n","    if similarity_score >= threshold:\n","        print(f\"Best match for '{predicted_class_1}': '{best_match}' with similarity score: {similarity_score}\")\n","        primitive_care= df_primitive_care[df_primitive_care['diagnose']==best_match]\n","        primitive_care = primitive_care['pid'].iloc[0]\n","        message = f\"Based on the symptoms you entered, there are chances that you are suffering from **{predicted_class_1}**.\\n\"\\\n","          f\"\\nThe primitive care we would suggest is **{primitive_care}** \\nThis recommendation is based on the symptoms you provided.\\n \"\\\n","        \"However, please note that this is not a substitute for professional medical advice. We strongly recommend consulting a healthcare professional \"\\\n","          \"for further clarification and a proper diagnosis. Your health is important, and a medical professional can provide personalized guidance and care.\"\n","        print(message)\n","\n","    else:\n","        print(f\" Diseases Predicted '{predicted_class_1}' in the is not monitored.\")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"3833a17f","metadata":{"id":"3833a17f"},"outputs":[],"source":["feature_names = X_train.columns.tolist()\n","syp = ['facial paresis','muscle twitch','chill','fever','cough','decreased body weight']"]},{"cell_type":"code","execution_count":null,"id":"27b9ace1","metadata":{"id":"27b9ace1"},"outputs":[],"source":["predicting_disease(syp,diagnose_list,feature_names)"]},{"cell_type":"code","execution_count":null,"id":"cbd2eead","metadata":{"id":"cbd2eead"},"outputs":[],"source":["syp = ['abscess bacterial','muscle twitch','chill','fever','barking cough']\n","predicting_disease(syp,diagnose_list,feature_names)\n","# in this case \"abscess bacterial\" is not the correct syp"]},{"cell_type":"code","execution_count":null,"id":"7d9f7327","metadata":{"id":"7d9f7327"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a5bef587","metadata":{"id":"a5bef587"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"85d89bf6","metadata":{"id":"85d89bf6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}