{"cells":[{"cell_type":"markdown","id":"5c59950d","metadata":{"id":"5c59950d"},"source":["# Modeling"]},{"cell_type":"code","source":["#!pip install fuzzywuzzy"],"metadata":{"id":"O4LBaharl1Ey","executionInfo":{"status":"ok","timestamp":1701074885708,"user_tz":480,"elapsed":122,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"id":"O4LBaharl1Ey","execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"id":"75435750","metadata":{"id":"75435750","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701074886931,"user_tz":480,"elapsed":921,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}},"outputId":"8bce162f-2b24-47eb-d919-158f32b24663"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, matthews_corrcoef\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, classification_report\n","import pickle\n","from sklearn.feature_selection import VarianceThreshold\n","from fuzzywuzzy import process\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import roc_auc_score, log_loss\n","\n","import os\n","#Connecting the driver\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')\n","\n","root_dir = '/content/drive/MyDrive/DAP/python_scripts'\n"]},{"cell_type":"code","source":[],"metadata":{"id":"nuSo5tqEdDB5","executionInfo":{"status":"ok","timestamp":1701074886932,"user_tz":480,"elapsed":6,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"id":"nuSo5tqEdDB5","execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"id":"ac49f510","metadata":{"id":"ac49f510","executionInfo":{"status":"ok","timestamp":1701074886932,"user_tz":480,"elapsed":4,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["# example of grid searching key hyperparametres for logistic regression\n","from sklearn.datasets import make_blobs\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":10,"id":"fd2f500a","metadata":{"id":"fd2f500a","executionInfo":{"status":"ok","timestamp":1701074886932,"user_tz":480,"elapsed":3,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def accuracy_measure(y_test, y_pred):\n","    sensitivity_overall = recall_score(y_test, y_pred, average='weighted')\n","    print('Sensitivity Overall Data:',sensitivity_overall)\n","\n","    precision_overall = precision_score(y_test, y_pred, average='weighted')\n","    print('Precision Overall Data:',precision_overall)\n","\n","    f1_overall = f1_score(y_test, y_pred, average='weighted')\n","    print('F1 Score Overall Data:',f1_overall)\n","\n","    # Cohen's Kappa statistic\n","    kappa = cohen_kappa_score(y_test, y_pred)\n","    print(\"Cohen's Kappa:\", kappa)\n","\n","    # Matthews Correlation Coefficient (MCC)\n","    mcc = matthews_corrcoef(y_test, y_pred)\n","    print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n","\n","    \"\"\"# Compute log loss\n","    logloss = log_loss(y_test, y_pred)\n","    print(f\"Log Loss: {logloss}\")\n","\n","    # AUC and ROC\n","    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Visualize predicted probabilities distribution\n","    plt.figure(figsize=(8, 6))\n","    sns.histplot(y_pred, bins=20, kde=True, color='skyblue')\n","    plt.xlabel('Predicted Probabilities')\n","    plt.ylabel('Frequency')\n","    plt.title('Distribution of Predicted Probabilities')\n","    plt.show()\"\"\"\n","\n","    # Confusion Matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","    print(cm)\n","\n","    \"\"\" # Printing Confusion Matrix calsswise\n","    unique_classes = np.unique(y_test)\n","\n","\n","\n","    # Initialize variables to store metrics\n","    total_tp = 0\n","    total_tn = 0\n","    total_fp = 0\n","    total_fn = 0\n","\n","    # Iterate over each class\n","    for cls in unique_classes:\n","        idx = (y_test == cls)\n","        true_positive = np.sum((y_pred[idx] == cls))\n","        true_negative = np.sum((y_pred != cls) & (y_test != cls))\n","        false_positive = np.sum((y_pred == cls) & (y_test != cls))\n","        false_negative = np.sum((y_pred != cls) & (y_test == cls))\n","\n","        total_tp += true_positive\n","        total_tn += true_negative\n","        total_fp += false_positive\n","        total_fn += false_negative\n","\n","        print(f\"\\nClass {cls} Metrics:\")\n","        print(f\"True Positive (TP): {true_positive}\")\n","        print(f\"True Negative (TN): {true_negative}\")\n","        print(f\"False Positive (FP): {false_positive}\")\n","        print(f\"False Negative (FN): {false_negative}\")\n","\n","    # Consolidated results\n","    print(\"\\nConsolidated Results:\")\n","    print(f\"Total True Positive (TP): {total_tp}\")\n","    print(f\"Total True Negative (TN): {total_tn}\")\n","    print(f\"Total False Positive (FP): {total_fp}\")\n","    print(f\"Total False Negative (FN): {total_fn}\")\"\"\"\n"]},{"cell_type":"markdown","id":"f680069d","metadata":{"id":"f680069d"},"source":["### Using various dimensionality reduction"]},{"cell_type":"code","execution_count":11,"id":"7c413bc3","metadata":{"id":"7c413bc3","executionInfo":{"status":"ok","timestamp":1701074886932,"user_tz":480,"elapsed":3,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def low_var():\n","    df_low_variance = pd.read_csv(os.path.join(root_dir,\"low_variance_features.csv\"))\n","    df_low_variance= df_low_variance.fillna(0)\n","    df_low_variance.isna().any()\n","    X = df_low_variance.drop('disease', axis=1)\n","    y = df_low_variance['disease']\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","    return X,y,X_train,y_train,X_test,X_val,y_test, y_val\n","\n","def rand_forest():\n","    df_training = pd.read_csv(os.path.join(root_dir,\"training_dataset_final.csv\"))\n","    df_feature = pd.read_csv(os.path.join(root_dir,\"feature_importance_df.csv\"))\n","    df_feature= df_feature.fillna(0)\n","    df_training= df_training.fillna(0)\n","    feature_list=(df_feature['Feature'].head(100)).tolist()\n","    df_training_important_Features = df_training[feature_list]\n","    df_training_important_Features['disease'] = df_training['disease']\n","    df_training_important_Features.info()\n","    X =df_training_important_Features.drop(columns=['disease'])\n","    y =df_training_important_Features['disease']\n","    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n","    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","    return X,y,X_train,y_train,X_test,X_val,y_test, y_val\n","\n"]},{"cell_type":"markdown","id":"9503b002","metadata":{"id":"9503b002"},"source":["# Logistic Regression"]},{"cell_type":"code","execution_count":12,"id":"eff6fa8d","metadata":{"id":"eff6fa8d","executionInfo":{"status":"ok","timestamp":1701074886932,"user_tz":480,"elapsed":3,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["def logistic_regression(X,y,X_train,y_train,X_test,X_val,y_test, y_val,pickle_file_name,var):\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_train)\n","\n","    classifier = LogisticRegression(max_iter=100)\n","    classifier.fit(X_scaled, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = classifier.predict(scaler.transform(X_test))\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    print(\"F1 Score:\", f1)\n","    logModel = LogisticRegression()\n","\n","    # Performing Grid Search using hyperparamters\n","    param_grid = [\n","        {'penalty' : ['l2'],\n","        'C' : np.logspace(-4, 4, 20),\n","        'solver': ['lbfgs', 'liblinear'],\n","        'max_iter' : [20,50, 100,1000]\n","        }\n","    ]\n","    clf = GridSearchCV(logModel, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)\n","    try:\n","        best_clf = clf.fit(X_train, y_train)\n","\n","    except UserWarning as warning:\n","        # Handle the warning as needed\n","        print(f\"Caught a UserWarning: {warning}\")\n","\n","    cv_results = pd.DataFrame(best_clf.cv_results_)\n","    cv_results.to_csv(os.path.join(root_dir,'LR_hyperparamters_results_'+var+'.csv'))\n","    print (f'Accuracy - : {best_clf.score(X,y):.3f}')\n","    print(best_clf)\n","    best_params = best_clf.best_params_\n","    print(\"Best hyperparameters:\", best_clf.best_params_)\n","    print(\"Best model:\", best_clf.best_estimator_)\n","\n","    #best_params = {'C':29.763514416313132, 'max_iter': 20, 'penalty': 'l2', 'solver': 'lbfgs'}\n","    best_params = best_clf.best_params_\n","    # Create a Logistic Regression model with the best hyperparameters\n","    best_log_model = LogisticRegression(**best_params)\n","\n","    # Train the model on the training data\n","    model = best_log_model.fit(X_train, y_train)\n","\n","    # Make predictions on the testing data\n","    y_pred = best_log_model.predict(X_test)\n","\n","    # Evaluate the performance of the model\n","    accuracy = accuracy_score(y_test, y_pred)\n","    print(\"Accuracy:\", accuracy)\n","    accuracy_measure(y_test, y_pred)\n","\n","    ### Validating the model\n","    print( \"####### Validating the model\" )\n","    predicted_class = best_log_model.predict(X_val)\n","    print(\"Predicted class:\", predicted_class)\n","\n","    accuracy = accuracy_score(y_val, predicted_class)\n","    print(\"Accuracy on the validation set:\", accuracy)\n","    accuracy_measure(y_val, predicted_class)\n","\n","    ### Saving the model with best parameters logistic regression\n","    print( \"####### Saving the model with best parameters logistic regression\" )\n","    # Save the model to a file using pickle\n","    with open(os.path.join(root_dir,pickle_file_name), 'wb') as file:\n","        pickle.dump(model, file)\n","    return y_pred\n"]},{"cell_type":"code","execution_count":13,"id":"b8b3b62d","metadata":{"id":"b8b3b62d","executionInfo":{"status":"ok","timestamp":1701074887090,"user_tz":480,"elapsed":161,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[],"source":["X,y,X_train,y_train,X_test,X_val,y_test, y_val = low_var()"]},{"cell_type":"code","execution_count":14,"id":"1be77672","metadata":{"id":"1be77672","outputId":"61e754f9-b1b1-4663-b582-c833b9ccf1a9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701074887090,"user_tz":480,"elapsed":9,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Done\n"]}],"source":["file_name = os.path.join(root_dir,'low_var_features_lr.txt')\n","with open(file_name, 'w') as fp:\n","    for item in X_train:\n","        # write each item on a new line\n","        fp.write(\"%s\\n\" % item)\n","    print('Done')"]},{"cell_type":"code","source":["y_test_lv =y_test"],"metadata":{"id":"0SnWLF9Cv7Ls","executionInfo":{"status":"ok","timestamp":1701074887090,"user_tz":480,"elapsed":8,"user":{"displayName":"ML.project Group 1","userId":"18243967642267011638"}}},"id":"0SnWLF9Cv7Ls","execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"72b04ff4","metadata":{"id":"72b04ff4","outputId":"4b6ec9b4-ed7f-403b-a80d-d92fefd4ddb0","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: 0.8932979676388365\n","Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["y_pred_lv = logistic_regression(X,y,X_train,y_train,X_test,X_val,y_test, y_val,'logistic_regression_model_lv.pkl','lv')"]},{"cell_type":"code","execution_count":null,"id":"8ea9f426","metadata":{"id":"8ea9f426"},"outputs":[],"source":["X,y,X_train,y_train,X_test,X_val,y_test, y_val = rand_forest()"]},{"cell_type":"code","execution_count":null,"id":"0e78dbfa","metadata":{"id":"0e78dbfa"},"outputs":[],"source":["file_name = os.path.join(root_dir,'rand_for_features_lr.txt')\n","with open(file_name, 'w') as fp:\n","    for item in X_train:\n","        # write each item on a new line\n","        fp.write(\"%s\\n\" % item)\n","    print('Done')"]},{"cell_type":"code","source":["y_test_rf =y_test"],"metadata":{"id":"bMipLFxZwBf0"},"id":"bMipLFxZwBf0","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"db0bce27","metadata":{"id":"db0bce27"},"outputs":[],"source":["y_pred_rf = logistic_regression(X,y,X_train,y_train,X_test,X_val,y_test, y_val,'logistic_regression_model_rd.pkl','rf')"]},{"cell_type":"code","execution_count":null,"id":"022079ef","metadata":{"id":"022079ef"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}